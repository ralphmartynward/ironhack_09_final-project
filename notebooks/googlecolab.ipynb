{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3ZK8aM84gBjA",
        "EvcZ4xbogGfE"
      ],
      "authorship_tag": "ABX9TyPRyS21yM/yd9QRqga0W7sn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ralphmartynward/ironhack_09_final-project/blob/main/notebooks/googlecolab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Drive connection"
      ],
      "metadata": {
        "id": "3ZK8aM84gBjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Admin/School/Online/IronHack/Cours/09 Final Project')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93n6DWgMUrwG",
        "outputId": "64f226ae-6a3a-4869-8f9e-f59130f6984b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install dependencies"
      ],
      "metadata": {
        "id": "EvcZ4xbogGfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install discord\n",
        "!pip install praw\n",
        "!pip install transformers\n",
        "!pip install openai\n",
        "!pip install instabot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_1NcdnC7VQK",
        "outputId": "4014f403-3599-4066-96c9-6d08a4493134"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting discord\n",
            "  Downloading discord-2.2.3-py3-none-any.whl (1.1 kB)\n",
            "Collecting discord.py>=2.2.3 (from discord)\n",
            "  Downloading discord.py-2.2.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp<4,>=3.7.4 (from discord.py>=2.2.3->discord)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.2.3->discord) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4,>=3.7.4->discord.py>=2.2.3->discord) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.7.4->discord.py>=2.2.3->discord)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp<4,>=3.7.4->discord.py>=2.2.3->discord)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp<4,>=3.7.4->discord.py>=2.2.3->discord)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4,>=3.7.4->discord.py>=2.2.3->discord)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4,>=3.7.4->discord.py>=2.2.3->discord)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4,>=3.7.4->discord.py>=2.2.3->discord) (3.4)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, discord.py, discord\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 discord-2.2.3 discord.py-2.2.3 frozenlist-1.3.3 multidict-6.0.4 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting praw\n",
            "  Downloading praw-7.7.0-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.4/189.4 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prawcore<3,>=2.1 (from praw)\n",
            "  Downloading prawcore-2.3.0-py3-none-any.whl (16 kB)\n",
            "Collecting update-checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.5.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.27.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.4)\n",
            "Installing collected packages: update-checker, prawcore, praw\n",
            "Successfully installed praw-7.7.0 prawcore-2.3.0 update-checker-0.18.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m139.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting instabot\n",
            "  Downloading instabot-0.117.0.tar.gz (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: certifi>=2019.11.28 in /usr/local/lib/python3.10/dist-packages (from instabot) (2022.12.7)\n",
            "Requirement already satisfied: chardet>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from instabot) (4.0.0)\n",
            "Requirement already satisfied: future>=0.18.2 in /usr/local/lib/python3.10/dist-packages (from instabot) (0.18.3)\n",
            "Collecting huepy>=1.2.1 (from instabot)\n",
            "  Downloading huepy-1.2.1.tar.gz (15 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from instabot) (3.4)\n",
            "Requirement already satisfied: pysocks>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from instabot) (1.7.1)\n",
            "Requirement already satisfied: pytz>=2019.3 in /usr/local/lib/python3.10/dist-packages (from instabot) (2022.7.1)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from instabot) (2.27.1)\n",
            "Collecting requests-toolbelt>=0.9.1 (from instabot)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting responses>=0.10.9 (from instabot)\n",
            "  Downloading responses-0.23.1-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting schedule>=0.6.0 (from instabot)\n",
            "  Downloading schedule-1.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from instabot) (1.16.0)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from instabot) (4.65.0)\n",
            "Requirement already satisfied: urllib3>=1.25.7 in /usr/local/lib/python3.10/dist-packages (from instabot) (1.26.15)\n",
            "Collecting mock>=3.0.5 (from instabot)\n",
            "  Downloading mock-5.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: moviepy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from instabot) (1.0.3)\n",
            "Requirement already satisfied: Pillow>=6.2.2 in /usr/local/lib/python3.10/dist-packages (from instabot) (8.4.0)\n",
            "Requirement already satisfied: pytest>=4.6.9 in /usr/local/lib/python3.10/dist-packages (from instabot) (7.2.2)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.1->instabot) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.1->instabot) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.1->instabot) (1.22.4)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.1->instabot) (2.25.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy>=1.0.1->instabot) (0.4.8)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6.9->instabot) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6.9->instabot) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6.9->instabot) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6.9->instabot) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6.9->instabot) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest>=4.6.9->instabot) (2.0.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->instabot) (2.0.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from responses>=0.10.9->instabot) (6.0)\n",
            "Collecting types-PyYAML (from responses>=0.10.9->instabot)\n",
            "  Downloading types_PyYAML-6.0.12.10-py3-none-any.whl (14 kB)\n",
            "Building wheels for collected packages: instabot, huepy\n",
            "  Building wheel for instabot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for instabot: filename=instabot-0.117.0-py3-none-any.whl size=101264 sha256=bc675475a1f126ad5da60a3478373077328ed1aa5f804088a34aa7b9e35514c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/bf/77/58ae7f57d53eb1e20faf980bbd060251dfd2816a1edff9150a\n",
            "  Building wheel for huepy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for huepy: filename=huepy-1.2.1-py3-none-any.whl size=26985 sha256=26f2b2ddaa55d2866567d5ba293a31f7f602edc7d36ed04696d089961c166fce\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/b3/80/bb3bc1a2d6d3ebbad79b4959f0da042ee6aa7f39b386a74465\n",
            "Successfully built instabot huepy\n",
            "Installing collected packages: types-PyYAML, huepy, schedule, mock, responses, requests-toolbelt, instabot\n",
            "Successfully installed huepy-1.2.1 instabot-0.117.0 mock-5.0.2 requests-toolbelt-1.0.0 responses-0.23.1 schedule-1.2.0 types-PyYAML-6.0.12.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get posts, process & classify, push to Discord server"
      ],
      "metadata": {
        "id": "qOJi5EojgNJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import discord\n",
        "import os\n",
        "import praw\n",
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from datetime import datetime, timedelta\n",
        "import torch\n",
        "import openai\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "\n",
        "# Define a function to get credentials\n",
        "def get_credentials(filename):\n",
        "    credentials = {}\n",
        "    with open(filename, 'r') as f:\n",
        "        for line in f:\n",
        "            key, value = line.strip().split('=')\n",
        "            credentials[key] = value.replace('\"', '')\n",
        "    return credentials\n",
        "\n",
        "# Load credentials\n",
        "credentials = get_credentials('cred.txt')\n",
        "\n",
        "# Initialize Reddit and OpenAI API Key\n",
        "reddit = praw.Reddit(client_id=credentials[\"REDDIT_CLIENT_ID\"], client_secret=credentials[\"REDDIT_SECRET\"], user_agent=\"my_user_agent\")\n",
        "openai.api_key = credentials[\"OPENAI_API_KEY\"]\n",
        "\n",
        "# Initialize model, tokenizer and sentiment analysis pipeline\n",
        "model_name = \"Yueh-Huan/news-category-classification-distilbert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, from_tf=True)\n",
        "nlp = pipeline('sentiment-analysis')\n",
        "\n",
        "# Category mapping\n",
        "label_dict = {\n",
        "'Parents': 0,'Wellness': 1,'Comedy': 3,'Parenting': 2,'Politics': 4,'Black Voices': 5,'Queer Voices': 6,'Entertainment': 7,'Culture & Arts': 8,'Tech': 9,'Religion': 10, 'Style & Beauty': 11, 'Healthy living': 12,'Travel': 13,'Green': 14,'Impact': 15,'Business': 16,'Divorce': 17,'Science': 18,'Sports': 19,'Latino Voices': 20,'World news': 21,'Home & Living': 22,'Media': 23,'U.S. news': 24,'Taste': 25,'Food & Drink': 26,'Weird News': 27,'Style': 28,'Women': 29,'Arts & Culture': 30,'Crime': 31,'Money': 32,'Weddings': 33,'Arts': 34,'Worldpost': 35, 'The WorldPost': 36,'Education': 37,'College': 38, 'Good news': 39,'Fifty': 40, 'Environment': 41\n",
        "}\n",
        "original_to_new_category = {\n",
        "'Parents': 'LIFESTYLE','Wellness': 'LIFESTYLE','Comedy': 'CULTURE','Parenting': 'LIFESTYLE','Politics': 'POLITICS','Black Voices': 'POLITICS','Queer Voices': 'POLITICS','Entertainment': 'CULTURE','Culture & Arts': 'CULTURE','Tech': 'TECH','Religion': 'CULTURE', 'Style & Beauty': 'LIFESTYLE', 'Healthy living': 'LIFESTYLE','Travel': 'LIFESTYLE','Green': 'ENVIRONMENT','Impact': 'NEWS & WORLD','Business': 'ECONOMY','Divorce': 'LIFESTYLE','Science': 'SCIENCE','Sports': 'SPORTS','Latino Voices': 'POLITICS','World news': 'NEWS & WORLD','Home & Living': 'LIFESTYLE','Media': 'CULTURE','U.S. news': 'NEWS & WORLD','Taste': 'LIFESTYLE','Food & Drink': 'LIFESTYLE','Weird News': 'NEWS & WORLD','Style': 'LIFESTYLE','Women': 'CULTURE','Arts & Culture': 'CULTURE','Crime': 'NEWS & WORLD','Money': 'ECONOMY','Weddings': 'LIFESTYLE','Arts': 'CULTURE','Worldpost': 'NEWS & WORLD', 'The WorldPost': 'NEWS & WORLD','Education': 'EDUCATION','College': 'EDUCATION', 'Good news': 'NEWS & WORLD','Fifty': 'LIFESTYLE', 'Environment': 'ENVIRONMENT'\n",
        "}\n",
        "index_to_category = {v: k for k, v in label_dict.items()}\n",
        "index_to_new_category = {k: original_to_new_category[v] for k, v in index_to_category.items()}\n",
        "\n",
        "def get_data():\n",
        "    yesterday = (datetime.now() - timedelta(days=1)).timestamp()\n",
        "    hot_posts = reddit.subreddit('nottheonion').hot(limit=20)\n",
        "\n",
        "    data = [\n",
        "        {\n",
        "            \"title\": post.title,\n",
        "            \"score\": post.score,\n",
        "            \"created\": pd.to_datetime(post.created, unit='s'),\n",
        "            \"url\": post.url\n",
        "        }\n",
        "        for post in hot_posts if post.created > yesterday\n",
        "    ]\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def classify_title(title):\n",
        "    inputs = tokenizer(title, return_tensors=\"pt\")\n",
        "    outputs = model(**inputs)\n",
        "    predicted_category_index = torch.argmax(outputs.logits, dim=-1).item()\n",
        "    predicted_category_original = index_to_category[predicted_category_index]\n",
        "    predicted_category_new = original_to_new_category[predicted_category_original]\n",
        "    return predicted_category_new\n",
        "\n",
        "def predict_sentiment(text):\n",
        "    result = nlp(text)[0]\n",
        "    return result['label']\n",
        "\n",
        "def generate_prompt(title):\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-003\", \n",
        "      prompt=f\"\"\"\n",
        "        Instructions:\n",
        "        Concept: \"{title}\". /imagine prompt: Start by interpreting the given \"{title}\". Create a scene that encapsulates the absurdity, humor, or irony contained within, but do not repeat the \"{title}\" verbatim. Convert your understanding of the context into a straightforward description using simple language.\n",
        "        You should imagine this scene as a photograph taken by renowned photographer Steve McCurry with a 50mm lens. This means you aim for an ultra-realistic, ultra-detailed 8K resolution image. Avoid figurative language and complex phrases. Include all key elements from the \"{title}\", like specific characters or locations, using clear and concise language.\n",
        "        Reflect the time period implied by the \"{title}\" in your image. For a touch of humor, include a character - a Garfield-like cat observing the scene, reacting with amusement or confusion.\n",
        "        Describe critical elements like lighting, color temperature, and facial expressions succinctly within four to five lines. Do not include any text in the image.\n",
        "        Finally, your prompt must conclude with the phrase \"Hyperrealistic, ultra-detailed, 8K resolution --v 5.1 --stylize 1000 --ar 6:5\". The prompt must also start with the phrase \"/imagine prompt:\".\n",
        "        \"\"\",\n",
        "      temperature=0.3,\n",
        "      max_tokens=200\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "def generate_hashtags(title):\n",
        "    response = openai.Completion.create(\n",
        "      engine=\"text-davinci-003\",\n",
        "      prompt=f\"Given the title \\\"{title}\\\", generate 30 relevant Instagram hashtags.\",\n",
        "      temperature=0.5,\n",
        "      max_tokens=60\n",
        "    )\n",
        "    hashtags = response.choices[0].text.strip().split(\", \")\n",
        "    hashtags = [tag.replace(\" \", \"\") for tag in hashtags]\n",
        "    return hashtags\n",
        "\n",
        "def add_category_and_sentiment(df):\n",
        "    df['category'] = df['title'].apply(classify_title)\n",
        "    df['bert_sentiment'] = df['title'].apply(predict_sentiment)\n",
        "    return df.sort_values(by=['score'], ascending=False)\n",
        "\n",
        "def add_prompt_and_hashtags(df):\n",
        "    df['prompt'] = df['title'].apply(generate_prompt)\n",
        "    df['hashtags'] = df['title'].apply(generate_hashtags)\n",
        "    return df\n",
        "\n",
        "# Get the data, classify it, and add category, sentiment, prompt, and hashtags\n",
        "df = get_data()\n",
        "df = add_category_and_sentiment(df)\n",
        "df = df.head(3)  # Keep only the first 3 rows\n",
        "df = add_prompt_and_hashtags(df)\n",
        "\n",
        "# Discord setup\n",
        "intents = discord.Intents.all()\n",
        "client = discord.Client(intents=intents)\n",
        "url_received = \"\"  # Global variable to store the received URL\n",
        "\n",
        "@client.event\n",
        "async def on_ready():\n",
        "    print('Logged in as {0}'.format(client.user))\n",
        "    channel = client.get_channel(1108705710872739924)  # Use your channel id\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        message = f\"Title: {row['title']}\\n\" \\\n",
        "                   f\"Score: {row['score']}\\n\" \\\n",
        "                   f\"URL: {row['url']}\\n\" \\\n",
        "                   f\"Category: {row['category']}\\n\" \\\n",
        "                   f\"Sentiment: {row['bert_sentiment']}\\n\" \\\n",
        "                   f\"Prompt: {row['prompt']}\\n\"\n",
        "        await channel.send(message)\n",
        "\n",
        "@client.event\n",
        "async def on_message(message):\n",
        "    if message.author.id == client.user.id:\n",
        "        return\n",
        "\n",
        "    if 'http' in message.content:\n",
        "        global url_received\n",
        "        url_received = message.content\n",
        "        print(f'Received URL: {url_received}')\n",
        "        await client.close()\n",
        "\n",
        "nest_asyncio.apply()\n",
        "client.run(credentials['DISCORD_TOKEN'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kclXhPi-fuTw",
        "outputId": "599da853-b1a8-4d2f-97ec-b1af52f8ce02"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
            "\n",
            "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "\u001b[30;1m2023-05-25 10:02:12\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "\u001b[30;1m2023-05-25 10:02:12\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.client\u001b[0m logging in using static token\n",
            "INFO:discord.client:logging in using static token\n",
            "\u001b[30;1m2023-05-25 10:02:13\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: a97c009abaacd8d32b5e01c0b61a789a).\n",
            "\u001b[30;1m2023-05-25 10:02:13\u001b[0m \u001b[34;1mINFO    \u001b[0m \u001b[35mdiscord.gateway\u001b[0m Shard ID None has connected to Gateway (Session ID: a97c009abaacd8d32b5e01c0b61a789a).\n",
            "INFO:discord.gateway:Shard ID None has connected to Gateway (Session ID: a97c009abaacd8d32b5e01c0b61a789a).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Purrposterous#8425\n",
            "Received URL: https://raw.githubusercontent.com/ralphmartynward/ironhack_09_final-project/main/images/newspurr.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(url_received)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZH5PzYLgOXT",
        "outputId": "dda7af8a-569c-428d-fd10-ea52e7f164b0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://raw.githubusercontent.com/ralphmartynward/ironhack_09_final-project/main/images/newspurr.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get Midjourney image & transform"
      ],
      "metadata": {
        "id": "pbBnyR5vTVbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import textwrap\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from instabot import Bot\n",
        "\n",
        "# Create the caption\n",
        "df['hashtags'] = df['title'].apply(generate_hashtags)\n",
        "df['caption'] = \"🐈 Full story here 👇 \" + df['url'] + \" \" + df['hashtags'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Download the image\n",
        "response = requests.get(url_received)\n",
        "image = Image.open(BytesIO(response.content))\n",
        "\n",
        "# Define the banner text\n",
        "text = df['title'].iloc[0]  # replace this with your caption\n",
        "\n",
        "# Select a font\n",
        "font_path = \"/content/drive/My Drive/Admin/School/Online/IronHack/Cours/09 Final Project/DejaVuSans-Bold.ttf\"  \n",
        "\n",
        "# Create the banner image (white background)\n",
        "banner_height = image.height // 5  # Adjust the height as needed\n",
        "banner = Image.new('RGB', (image.width, banner_height), \"white\")\n",
        "\n",
        "# Create a drawing object for the banner\n",
        "draw = ImageDraw.Draw(banner)\n",
        "\n",
        "# Calculate the maximum width for the text\n",
        "max_text_width = banner.width - 20  # Deducting a margin\n",
        "\n",
        "# Initial font size (will be adjusted later)\n",
        "font_size = banner_height // 5  # Adjust this as needed\n",
        "\n",
        "# Wrap the text initially\n",
        "wrapper = textwrap.TextWrapper(width=1)  # Initial width (will be adjusted later)\n",
        "wrapped_text = wrapper.fill(text)\n",
        "\n",
        "# Create the font object (initially)\n",
        "font = ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "# Calculate the width of the wrapped text (initially)\n",
        "text_width, text_height = draw.textsize(wrapped_text, font=font)\n",
        "\n",
        "# Decrease the font size until the text fits into the desired width\n",
        "while text_height > banner_height:\n",
        "    font_size -= 1\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "    wrapper.width = banner.width // font_size\n",
        "    wrapped_text = wrapper.fill(text)\n",
        "    text_width, text_height = draw.textsize(wrapped_text, font=font)\n",
        "\n",
        "# Calculate the position for the centered text\n",
        "text_x = (banner.width - text_width) // 2\n",
        "text_y = (banner.height - text_height) // 2\n",
        "\n",
        "# Draw the wrapped text on the banner\n",
        "draw.multiline_text((text_x, text_y), wrapped_text, fill=\"black\", font=font)\n",
        "\n",
        "# Load and place the emoji image\n",
        "emoji_image = Image.open('/content/drive/My Drive/Admin/School/Online/IronHack/Cours/09 Final Project/images/facepalm.png')\n",
        "emoji_size = banner_height // 2  # You may need to adjust the size\n",
        "emoji_margin = banner_height // 6\n",
        "emoji_image = emoji_image.resize((emoji_size, emoji_size)) \n",
        "banner.paste(emoji_image, (banner.width - emoji_image.width - emoji_margin, banner.height - emoji_image.height - emoji_margin))\n",
        "\n",
        "# Append the banner to the bottom of the image\n",
        "output_image = Image.new('RGB', (image.width, image.height + banner.height))\n",
        "output_image.paste(image, (0, 0))\n",
        "output_image.paste(banner, (0, image.height))\n",
        "\n",
        "# Initialize a counter for images\n",
        "image_counter = 1\n",
        "\n",
        "# Save the output image with a dynamic filename\n",
        "output_image.save(f\"output_image{image_counter}.jpg\")\n",
        "image_counter += 1  # increment the counter\n",
        "\n",
        "# ----------------------------------------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "eaRYUZtymE3g"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post to IG"
      ],
      "metadata": {
        "id": "_up17SqDd1m3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from instabot import Bot\n",
        "\n",
        "# Load the credentials\n",
        "credentials = {}\n",
        "with open(\"cred.txt\", \"r\") as file:\n",
        "    for line in file:\n",
        "        key, value = line.strip().split('=')\n",
        "        credentials[key] = value.strip('\\\"')\n",
        "\n",
        "# Retrieve the Instagram credentials from the dictionary\n",
        "ig_username = credentials[\"ig_username\"]\n",
        "ig_password = credentials[\"ig_password\"]\n",
        "\n",
        "caption = df.loc[0, \"caption\"]\n",
        "\n",
        "# Initialize and login to the bot\n",
        "bot = Bot()\n",
        "bot.login(username=ig_username, password=ig_password)\n",
        "\n",
        "# Initialize a counter for images\n",
        "image_counter = 1\n",
        "\n",
        "# Upload a picture with a dynamic filename\n",
        "while True:\n",
        "    try:\n",
        "        bot.upload_photo(f\"output_image{image_counter}.jpg\", caption=caption)\n",
        "        break\n",
        "    except Exception as e:\n",
        "        if str(e) == \"429\":\n",
        "            print(\"Too many requests. Sleeping for 5 minutes.\")\n",
        "            time.sleep(300)  # Sleep for 5 minutes (300 seconds)\n",
        "        else:\n",
        "            print(\"Error:\", e)\n",
        "            break\n",
        "\n",
        "image_counter += 1  # increment the counter\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        },
        "id": "i5W1L7YweWY9",
        "outputId": "ce06a24a-6139-4ab7-dd2a-496eff6728f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-05-25 15:03:31,928 - INFO - Instabot version: 0.117.0 Started\n",
            "2023-05-25 15:03:31,928 - INFO - Instabot version: 0.117.0 Started\n",
            "INFO:instabot version: 0.117.0:Instabot version: 0.117.0 Started\n",
            "DEBUG:instabot version: 0.117.0:Bot imported from /usr/local/lib/python3.10/dist-packages/instabot/bot/bot.py\n",
            "2023-05-25 15:03:31,947 - INFO - Not yet logged in starting: PRE-LOGIN FLOW!\n",
            "2023-05-25 15:03:31,947 - INFO - Not yet logged in starting: PRE-LOGIN FLOW!\n",
            "INFO:instabot version: 0.117.0:Not yet logged in starting: PRE-LOGIN FLOW!\n",
            "DEBUG:instabot version: 0.117.0:POST to endpoint: accounts/get_prefill_candidates/ returned response: <Response [429]>\n",
            "DEBUG:instabot version: 0.117.0:Responsecode indicates error; response content: b'{\"message\":\"Please wait a few minutes before you try again.\",\"status\":\"fail\"}'\n",
            "2023-05-25 15:03:32,519 - ERROR - Request returns 429 error!\n",
            "2023-05-25 15:03:32,519 - ERROR - Request returns 429 error!\n",
            "ERROR:instabot version: 0.117.0:Request returns 429 error!\n",
            "2023-05-25 15:03:32,526 - WARNING - That means 'too many requests'. I'll go to sleep for 5 minutes.\n",
            "2023-05-25 15:03:32,526 - WARNING - That means 'too many requests'. I'll go to sleep for 5 minutes.\n",
            "WARNING:instabot version: 0.117.0:That means 'too many requests'. I'll go to sleep for 5 minutes.\n",
            "DEBUG:instabot version: 0.117.0:POST to endpoint: accounts/get_prefill_candidates/ returned response: <Response [429]>\n",
            "DEBUG:instabot version: 0.117.0:Responsecode indicates error; response content: b'{\"message\":\"Please wait a few minutes before you try again.\",\"status\":\"fail\"}'\n",
            "2023-05-25 15:08:32,823 - ERROR - Request returns 429 error!\n",
            "2023-05-25 15:08:32,823 - ERROR - Request returns 429 error!\n",
            "ERROR:instabot version: 0.117.0:Request returns 429 error!\n",
            "2023-05-25 15:08:32,828 - WARNING - That means 'too many requests'. I'll go to sleep for 10 minutes.\n",
            "2023-05-25 15:08:32,828 - WARNING - That means 'too many requests'. I'll go to sleep for 10 minutes.\n",
            "WARNING:instabot version: 0.117.0:That means 'too many requests'. I'll go to sleep for 10 minutes.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cba89d969f8a>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Initialize and login to the bot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mbot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mbot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mig_username\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mig_password\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Initialize a counter for images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instabot/bot/bot.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self, **args)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"proxy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproxy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instabot/api/api.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self, username, password, force, proxy, use_cookie, use_uuid, cookie_fname, ask_for_code, set_device, generate_all_uuids, is_threaded)\u001b[0m\n\u001b[1;32m    263\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mgenerate_all_uuids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_all_uuids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_login_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m             data = json.dumps(\n\u001b[1;32m    267\u001b[0m                 {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instabot/api/api.py\u001b[0m in \u001b[0;36mpre_login_flow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpre_login_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpre_login_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlogin_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjust_logged_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp_refresh_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1800\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instabot/api/api_login.py\u001b[0m in \u001b[0;36mpre_login_flow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# /api/v1/accounts/get_prefill_candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_prefill_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;31m# /api/v1/qe/sync (server_config_retrieval)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instabot/api/api.py\u001b[0m in \u001b[0;36mget_prefill_candidates\u001b[0;34m(self, login)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_prefill_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_prefill_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_account_family\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instabot/api/api_login.py\u001b[0m in \u001b[0;36mget_prefill_candidates\u001b[0;34m(self, login)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_csrftoken\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"accounts/get_prefill_candidates/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instabot/api/api.py\u001b[0m in \u001b[0;36msend_request\u001b[0;34m(self, endpoint, post, login, with_signature, headers, extra_sig, timeout_minutes)\u001b[0m\n\u001b[1;32m    575\u001b[0m                 )\n\u001b[1;32m    576\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout_minutes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m                 return self.send_request(\n\u001b[0m\u001b[1;32m    578\u001b[0m                     \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m                     \u001b[0mpost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/instabot/api/api.py\u001b[0m in \u001b[0;36msend_request\u001b[0;34m(self, endpoint, post, login, with_signature, headers, extra_sig, timeout_minutes)\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0;34m\"for {} minutes.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout_minutes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 )\n\u001b[0;32m--> 576\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout_minutes\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m                 return self.send_request(\n\u001b[1;32m    578\u001b[0m                     \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}